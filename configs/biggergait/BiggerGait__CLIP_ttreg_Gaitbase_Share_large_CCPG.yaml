data_cfg:
  dataset_name: CCPG
  # TODO
  dataset_root: /data/CCPG/Released/CCPG-ratio-pkl # use datasets/pretreatment_rgb.py for data preprocessing!
  dataset_partition: ./datasets/CCPG/CCPG.json
  data_in_use: [True, False] # images / real_ratios
  num_workers: 8
  remove_no_gallery: false # Remove probe if no gallery for it
  test_dataset_name: CCPG

evaluator_cfg:
  enable_float16: true
  restore_ckpt_strict: False # Rename some module name for clarity, so it is fasle.
  restore_hint: 30000 # BiggerGait__SmallDINOv2_Gaitbase_84Frame30_448224_6432HPP32_NoAlign_Sep12B_WiMask_2B_6G-30000.pt in HuggingFace
  save_name: BiggerGait__CLIP-Large_Gaitbase_Share
  eval_func: evaluate_CCPG
  sampler:
    batch_shuffle: false
    batch_size: 4 # GPUs number
    sample_type: all_ordered # all indicates whole sequence used to test, while ordered means input sequence by its natural order; Other options:   fixed_unordered
    frames_all_limit: 250 # limit the number of sampled frames to prevent out of memory
  metric: euc # cos
  transform:
    - type: BaseRgbTransform

loss_cfg:
  - loss_term_weight: 1.0
    margin: 0.2
    type: TripletLoss
    log_prefix: triplet
  - loss_term_weight: 1.0
    scale: 16
    type: CrossEntropyLoss
    log_prefix: softmax
    log_accuracy: true

model_cfg:
  chunk_size: 4
  model: BiggerGait__CLIP_ttreg
  pretrained_lvm: pretrained_LVMs/openai-clip-vit-large-patch14
  pretrained_mask_branch: pretrained_LVMs/openai-clip-vit-large-patch14/MaskBranch.pt
  
  image_size: 224
  sils_size: 32
  source_dim: 1024
  num_FPN: 6
  num_unknown: 16
  
  # TTR Params
  ttr_config_path: ./pretrained_LVMs/clip_vit_large_ttr.yaml 
  register_neurons_path: ./pretrained_LVMs/register_neurons_clip_large.pt
  num_registers: 5
  ttr_scale: 1.0
  ttr_normal_values: zero
  gradient_checkpointing: false

  Mask_Branch:
    source_dim: 1024
    target_dim: 2
    p: 0.
    softmax: True
    Relu: False
    Up: True

  backbone_cfg:
    type: ResNet9
    block: BasicBlock_Time
    in_channel: 16
    channels: [64, 128, 256, 512]
    layers: [1, 1, 1, 1]
    strides: [1, 2, 1, 1]
    maxpool: false
  SeparateFCs:
    in_channels: 512
    out_channels: 256
    parts_num: 32
  SeparateBNNecks:
    class_num: 100
    in_channels: 256
    parts_num: 32
  bin_num: [32]

optimizer_cfg:
  lr: 0.1
  momentum: 0.9
  solver: SGD
  weight_decay: 0.0005

scheduler_cfg:
  gamma: 0.1
  milestones: # Learning Rate Reduction at each milestones
    - 15000
    - 25000
  scheduler: MultiStepLR

trainer_cfg:
  find_unused_parameters: True
  enable_float16: true # half_percesion float for memory reduction and speedup
  fix_BN: false
  log_iter: 100
  with_test: true
  restore_ckpt_strict: true
  restore_hint: 0
  save_iter: 10000
  save_name: BiggerGait__CLIP-Large_Gaitbase_Share
  sync_BN: true
  total_iter: 30000
  sampler:
    batch_shuffle: true
    batch_size:
      - 8 # TripletSampler, batch_size[0] indicates Number of Identity
      - 4 #                 batch_size[1] indicates Samples sequqnce for each Identity
    frames_num_fixed: 30 # fixed frames number for training
    frames_skip_num: 4
    frames_num_max: 40 # max frames number for unfixed training
    frames_num_min: 20 # min frames number for unfixed traing
    sample_type: fixed_unordered # fixed control input frames number, unordered for controlling order of input tensor; Other options: unfixed_ordered or all_ordered
    type: TripletSampler
  transform:
    - type: Compose
      trf_cfg:
        - type: RandomHorizontalFlip
        - type: BaseRgbTransform
          mean: [122.7709383, 116.7460125, 104.09373615000001] # [0.48145466, 0.4578275, 0.40821073]
          std: [68.5005327, 66.6321579, 70.32316304999999] # [0.26862954, 0.26130258, 0.27577711]
